{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "newAlyce.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyM5SzqBTlkztaXMvVmTc7Bl"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xO6XkOFbkCMo",
        "colab_type": "text"
      },
      "source": [
        "# Alyce : An A.I fine tuned Screenplay writer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OzjEqtpkF14",
        "colab_type": "text"
      },
      "source": [
        "### Project Setting Up Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDmmHrwHkKfH",
        "colab_type": "text"
      },
      "source": [
        "If you are experiencing any problem while running the below code then Goto the '**Runtime**' menu and select '**Factory Reset Runtime**' to reset the notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJh5zAbZj_ii",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/16cs009/alycetmp.git\n",
        "import os\n",
        "os.chdir(\"/content/alycetmp\")\n",
        "!pip install -r requirements.txt\n",
        "!python -m spacy download en\n",
        "import neuralcoref\n",
        "import nltk\n",
        "!python -m nltk.downloader all\n",
        "\n",
        "from transformers.modeling_gpt2 import GPT2LMHeadModel\n",
        "_ = GPT2LMHeadModel.from_pretrained(\"gpt2-medium\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERJHn-zBGJp5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from os.path import exists, join, basename, splitext\n",
        "\n",
        "git_repo_url = 'https://github.com/mozilla/TTS.git'\n",
        "project_name = splitext(basename(git_repo_url))[0]\n",
        "if not exists(project_name):\n",
        "  !git clone -q {git_repo_url}\n",
        "  !cd {project_name} && git checkout Tacotron2-iter-260K-824c091\n",
        "  !pip install -q gdown Unidecode==0.4.20 git+git://github.com/bootphon/phonemizer@master localimport\n",
        "  !apt-get install -y espeak\n",
        "git_repo_url = 'https://github.com/erogol/WaveRNN.git'\n",
        "project_name = splitext(basename(git_repo_url))[0]\n",
        "if not exists(project_name):\n",
        "  !git clone -q {git_repo_url}\n",
        "  !cd {project_name} && git checkout 8a1c152 && pip install -q -r requirements.txt\n",
        "\n",
        "  \n",
        "import sys\n",
        "sys.path.append('TTS')\n",
        "sys.path.append('WaveRNN')\n",
        "\n",
        "!mkdir -p wavernn_models tts_models\n",
        "wavernn_pretrained_model = 'wavernn_models/checkpoint_433000.pth.tar'\n",
        "if not exists(wavernn_pretrained_model):\n",
        "  !gdown -O {wavernn_pretrained_model} https://drive.google.com/uc?id=12GRFk5mcTDXqAdO5mR81E-DpTk8v2YS9\n",
        "wavernn_pretrained_model_config = 'wavernn_models/config.json'\n",
        "if not exists(wavernn_pretrained_model_config):\n",
        "  !gdown -O {wavernn_pretrained_model_config} https://drive.google.com/uc?id=1kiAGjq83wM3POG736GoyWOOcqwXhBulv\n",
        "    \n",
        "# TTS\n",
        "tts_pretrained_model = 'tts_models/checkpoint_261000.pth.tar'\n",
        "if not exists(tts_pretrained_model):\n",
        "  !gdown -O {tts_pretrained_model} https://drive.google.com/uc?id=1otOqpixEsHf7SbOZIcttv3O7pG0EadDx\n",
        "tts_pretrained_model_config = 'tts_models/config.json'\n",
        "if not exists(tts_pretrained_model_config):\n",
        "  !gdown -O {tts_pretrained_model_config} https://drive.google.com/uc?id=1IJaGo0BdMQjbnCcOL4fPOieOEWMOsXE-"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ALWi4QBkRv_",
        "colab_type": "text"
      },
      "source": [
        "### Running Alyce"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0czakrxkUt4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import neuralcoref\n",
        "import nltk\n",
        "\n",
        "import spacy\n",
        "import neuralcoref\n",
        "import sys\n",
        "import re\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tag import pos_tag\n",
        "from nltk.corpus import stopwords\n",
        "from Datasets import datasets\n",
        "\n",
        "nlp = spacy.load('en')\n",
        "coref = neuralcoref.NeuralCoref(nlp.vocab)\n",
        "nlp.add_pipe(coref, name='neuralcoref')\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import plot_generator\n",
        "tokenizer, model, PPLM = plot_generator.initialize(np,torch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9NzD6gqGr14",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import wavernn_wrapper\n",
        "WaveRNN_libraries = wavernn_wrapper.initializeWaveRNN(\"/content/alycetmp/WaveRNN\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRge0p30kdWA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def phaseI_processStory(story):\n",
        "\t# Returns a list of list with the following as the content of list inside the list :>\n",
        "\t# 1. Dialogue-Replaced sentence from story\n",
        "\t# 2. Type of the Sentence : NARRATION, DIALOGUE, NEWLINE\n",
        "\t# 3. YES or NO string indicating whether NeuralCoref was applied to resolve reference\n",
        "\t# 4. If NeuralCoref was applied then The object It returned\n",
        "\t# 5. If the sentence is of type dialogue then its speaker\n",
        "\t# 6. If the sentence is of type dialogue then the corresponding dialogue\n",
        "\tdialogues = re.findall(r'\\\"(.+?)\\\"',story)\n",
        "\tdialogue_count = 0\n",
        "\tfor dialogue in dialogues:\n",
        "\t\tqt_mark = \"\\\"\" if(story.find(\"\\\"\"+dialogue+\"\\\"\")!=-1) else '\\''\n",
        "\t\tstory = story.replace(qt_mark+dialogue+qt_mark,\"<-DIALOGUE-#\"+str(dialogue_count)+\"#->\")\n",
        "\t\tdialogue_count = dialogue_count + 1\n",
        "\n",
        "\tstorylist = []\n",
        "\tfor paragraph in story.split(\"\\n\"):\n",
        "\t\tfor sentence in paragraph.split(\".\"):\n",
        "\t\t\tif(len(sentence.strip())!=0):\n",
        "\t\t\t\ttmp_slist = list()\n",
        "\t\t\t\ttmp_slist.append(sentence)\n",
        "\t\t\t\tif(sentence.find(\"<-DIALOGUE-#\")!=-1):\n",
        "\t\t\t\t\ttmp_slist.append(\"DIALOGUE\")\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\ttmp_slist.append(\"NARRATION\")\n",
        "\t\t\t\ttmp_slist.append(\"NO\")\n",
        "\t\t\t\ttmp_slist.append(\" \")\n",
        "\t\t\t\ttmp_slist.append(\" \")\n",
        "\t\t\t\ttmp_slist.append(\" \")\n",
        "\t\t\t\tstorylist.append(tmp_slist)\n",
        "\t\tstorylist.append([\"\\\\n\",\"NEWLINE\",\" \",\" \",\" \",\" \"])\n",
        "\n",
        "\tfor i in range(len(storylist)):\n",
        "\t\tif(storylist[i][1]==\"DIALOGUE\" and i>0):\n",
        "\t\t\twords = storylist[i][0].upper().split(\" \")\n",
        "\t\t\tif(\"HE\" in words or \"SHE\" in words or \"HIM\" in words or \"HER\" in words):\n",
        "\t\t\t\tj=i-1\n",
        "\t\t\t\twhile(j>0):\n",
        "\t\t\t\t\tif(storylist[j][1]!=\"NEWLINE\"):\n",
        "\t\t\t\t\t\tbreak\n",
        "\t\t\t\t\tj=j-1\n",
        "\t\t\t\tcoreference_resolver_result = nlp(\".\".join([storylist[j][0],storylist[i][0]]))\n",
        "\t\t\t\tstorylist[i][0] = coreference_resolver_result._.coref_resolved.split(\".\")[-1]\n",
        "\t\t\t\tstorylist[i][2] = \"YES\"\n",
        "\t\t\t\tstorylist[i][3] = str(coreference_resolver_result._.coref_clusters)\n",
        "\n",
        "\tk = 0\n",
        "\ts1 = {}\n",
        "\tfor i in range(len(storylist)):\n",
        "\t\tif(storylist[i][1]==\"DIALOGUE\"):\n",
        "\t\t\tdialogue_holder = re.findall(r'<-DIALOGUE-#[0-9][0-9]*#->',storylist[i][0])[0]\n",
        "\t\t\tdialogue_containing_resolved_sentence = storylist[i][0].replace(dialogue_holder,\"\").strip()\n",
        "\t\t\tstorylist[i][5] = dialogues[k]\n",
        "\t\t\tstop_words = set(stopwords.words(\"english\"))\n",
        "\t\t\td1 = nltk.word_tokenize(dialogue_containing_resolved_sentence.lower())\n",
        "\t\t\td2 = [j for j in d1 if not j in stop_words]\n",
        "\t\t\tfor w in nltk.pos_tag(d2):\n",
        "\t\t\t\tif(w[1]==\"NN\"):\n",
        "\t\t\t\t\tif(w[0].lower() in s1.keys()):\n",
        "\t\t\t\t\t\ts1[w[0].lower()] = s1[w[0].lower()]+1\n",
        "\t\t\t\t\telse:\n",
        "\t\t\t\t\t\ts1[w[0].lower()] = 1\n",
        "\t\t\tk = k + 1\n",
        "\tcharacter_list = [k for k in s1.keys() if s1[k]>1]\n",
        "\n",
        "\tk = 0\n",
        "\tfor i in range(len(storylist)):\n",
        "\t\tif(storylist[i][1]==\"DIALOGUE\"):\n",
        "\t\t\tstorylist[i][4]=\"UNKNOWN\"\n",
        "\t\t\tsentence = \" \".join([ w if w not in datasets.wordList else \"said\" for w in storylist[i][0].split(\" \")])\n",
        "\t\t\tfor subsentence in sentence.split(\",\"):\n",
        "\t\t\t\tif(subsentence.find(\"said\")!=-1):\n",
        "\t\t\t\t\tfor word in subsentence.split(\" \"):\n",
        "\t\t\t\t\t\tif(word.strip().lower() in character_list):\n",
        "\t\t\t\t\t\t\tstorylist[i][4]=word.strip()\n",
        "\t\t\t\t\t\t\tbreak\n",
        "\t\t\t\t\tbreak\n",
        "\t\t\tk = k + 1\n",
        "\treturn storylist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vbni-ZwAkiZg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def phaseII_processStory(storylist):\n",
        "\t# Returns a list of list with the following as the content of list inside the list :>\n",
        "\t# 1. Dialogue-Replaced sentence from story or Generated PLOT\n",
        "\t# 2. Type of the Sentence : NARRATION, DIALOGUE, NEWLINE, PLOT\n",
        "\t# 3. YES or NO string indicating whether NeuralCoref was applied to resolve reference\n",
        "\t# 4. If NeuralCoref was applied then The object It returned\n",
        "\t# 5. If the sentence is of type dialogue then its speaker\n",
        "\t# 6. If the sentence is of type dialogue then the corresponding dialogue\n",
        "\tplotwords = []\n",
        "\ttmp = list()\n",
        "\tnew_storylist = []\n",
        "\ttmp_storylist = []\n",
        "\tp_count = 0\n",
        "\tfor sentences in storylist:\n",
        "\t\ttmp_storylist.append(sentences)\n",
        "\t\tif sentences[1]==\"NEWLINE\":\n",
        "\t\t\tif len(tmp_storylist)>0:\n",
        "\t\t\t\tnew_storylist.append([p_count,\"PLOT\",\"\",\"\",\"\",\"\"])\n",
        "\t\t\t\tp_count = p_count + 1\n",
        "\t\t\tnew_storylist += tmp_storylist\n",
        "\t\t\ttmp_storylist = []\n",
        "\t\t\tplotwords.append(tmp)\n",
        "\t\t\ttmp = list()\n",
        "\t\telif sentences[1]==\"NARRATIVE\":\n",
        "\t\t\ttmp = tmp + sentences[0].split(\" \")\n",
        "\t\telse:\n",
        "\t\t\ttmp = tmp + sentences[0].split(\" \")\n",
        "\t\t\ttmp = tmp + sentences[5].split(\" \")\n",
        "\t#print(new_storylist)\n",
        "\tfor i in range(len(plotwords)):\n",
        "\t\tplotwords[i] = list(dict.fromkeys([ (\"\".join([tmpchar for tmpchar in word if tmpchar.isalpha()==True])).lower() for word in plotwords[i] if word.find(\"<-DIALOGUE-#\")==-1 and len(word)>2 and word not in datasets.wordList]))\n",
        "\t\tplotwords[i].sort()\n",
        "\tplot_desc = []\n",
        "\tprint(\"Required to genearte \"+str(len(plotwords)+1)+\" words!...\")\n",
        "\tfor i in plotwords:\n",
        "\t\tif len(i)>0:\n",
        "\t\t\tprint(\"Generating Plot!....\")\n",
        "\t\t\tplot_desc.append(plot_generator.generate_plot(np,torch,tokenizer,model,PPLM,[i],20,1)[0])\n",
        "\t\t\tprint(\"Generating Plot Completed!....\")\n",
        "\t\telse:\n",
        "\t\t\tplot_desc.append('')\n",
        "\tnew_storylist = [sentences if sentences[1]!=\"PLOT\" else [plot_desc[sentences[0]],\"PLOT\",\"\",\"\",\"\",\"\"] for sentences in new_storylist]\n",
        "\treturn new_storylist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XV6vkE3klqH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_to_html(output):\n",
        "  responseString = \"\"\n",
        "  for d in output:\n",
        "    if(d[1]==\"NARRATION\"):\n",
        "      responseString = responseString + d[0]\n",
        "    elif(d[1]==\"NEWLINE\"):\n",
        "      responseString = responseString + \"<hr/>\"\n",
        "    elif(d[1]==\"PLOT\"):\n",
        "      responseString = responseString + \"<br/><h5>\"+d[0]+\"</h5>\"\n",
        "    else:\n",
        "      responseString = responseString + \"<br/><font color='red'><b>\"+d[4]+\"</b> : \"+d[5]+\"</font>\"\n",
        "      ad = \"\"\n",
        "      for t in d[0].split(\",\"):\n",
        "        if(t.lower().find(\"said\")==-1 and t.find(\"<-DIALOGUE-\")==-1):\n",
        "          ad = ad + t\n",
        "      if(len(ad)>0):\n",
        "        responseString = responseString + \"<font color='green'>((\"+ad+\"))</font>\"\n",
        "      responseString = responseString+\"</br>\"\n",
        "  return responseString"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GjM78JykuZp",
        "colab_type": "text"
      },
      "source": [
        "## Main Program"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AetPp6UGkoqo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Started!....\")\n",
        "iFile = open(\"/content/alycetmp/public/story/story01.txt\")\n",
        "story = [s.replace('\\n','') for s in iFile.readlines()]\n",
        "iFile.close()\n",
        "story = \"\\n\".join(story)\n",
        "data = phaseI_processStory(story)\n",
        "data = phaseII_processStory(data)\n",
        "response = convert_to_html(data)\n",
        "print(\"<br><hr>\")\n",
        "print(response)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}